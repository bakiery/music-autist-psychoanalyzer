{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8992e8",
   "metadata": {},
   "source": [
    "# üéß music-autist-psychoanalyzer ‚Äì Demo Notebook\n",
    "\n",
    "Welcome to the most brutally online, neurotic, and *terminally unfiltered* music psychoanalysis engine.  \n",
    "**Powered by GPT-OSS 20B, running locally via Ollama.**\n",
    "\n",
    "> **WARNING:** This notebook can melt your RAM (32GB+ is highly recommended).  \n",
    "> Results are savage, non-PC, and designed for terminally online users‚Äî*not* for HR, LinkedIn, or normies.\n",
    "\n",
    "---\n",
    "\n",
    "## üèÅ Instructions\n",
    "\n",
    "1. Make sure [Ollama](https://ollama.com/download) is installed & running, with GPT-OSS 20B or smaller model downloaded.\n",
    "2. Paste your **Spotify/Last.fm top artists or tracks** below (90 days, 6 months, 12 months, whatever).\n",
    "3. Run the code, and receive a savage, data-driven, clinical meme roast.\n",
    "\n",
    "---\n",
    "\n",
    "## üéº Paste your music data in the code blocks provided\n",
    "\n",
    "Insert your *own* artists/tracks in the code blocks in this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Run the psychoanalysis\n",
    "\n",
    "All set? Run the code cell below for your results.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùó Disclaimer\n",
    "\n",
    "- **This is a meme-tier, research-only project.**\n",
    "- Output may be offensive, NSFW, or psycho-clinical. If you‚Äôre easily offended or work in HR, close this notebook.\n",
    "- Not intended for therapy, diagnosis, or social climbing.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb6564",
   "metadata": {},
   "source": [
    "    -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24115980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup and RAM warning\n",
    "\n",
    "import ollama\n",
    "\n",
    "print(\"‚ö†Ô∏è  This model will EAT your RAM (32GB+ recommended for GPT-OSS 20B). Use smaller models if on a potato.\")\n",
    "\n",
    "# Optionally check if Ollama is running (does nothing if not)\n",
    "import subprocess\n",
    "try:\n",
    "    subprocess.check_output([\"pgrep\", \"ollama\"])\n",
    "except Exception:\n",
    "    print(\"‚ùå Ollama not running! Please launch it before continuing.\")\n",
    "\n",
    "\n",
    "\n",
    "# 2. Paste your music data\n",
    "# 90-day Last.fm/Spotify example data (replace with your own)\n",
    "music_data = \"\"\"\n",
    "Kanye West, Danielle Dax, X CLUB., Funk Assault, Yes, Genlog, EFESIAN, TAFKAMP, Virgin Prunes,\n",
    "Chl√§r, Toni Moralez, Depeche Mode, Strawberry Switchblade, Marusha, Xmal Deutschland, Paul Johnson,\n",
    "Pretty Sick, Aurat, Sa√¢da Bonaire, Mandala, Visage, Scooter, DJ Assault, DJ Deeon, Ellen Allien,\n",
    "Talismann, Klangkuenstler, Siouxsie and the Banshees, Death in June, Nuclear Hyde, Imani Coppola,\n",
    "RaveShine, Alan Fitzpatrick, Commander Tom, WestBam, Da Brat, NightGTA, Wax Master Maurice, Duty Paid,\n",
    "Paradisio, Da Rick, Alan Fitzpatrick, Area, Angel Heart, Awdha, DJ Misjah & DJ Groovehead, Thunderball,\n",
    "Killing Joke, Bauhaus, The Cure, Playboi Carti\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 3. Build and send the prompt\n",
    "prompt = f\"\"\"\n",
    "You are a clinically autistic, highly unhinged, non-PC psychoanalyst.\n",
    "Analyze this user's raw music taste and generate a detailed, savage psycho-meme roast including:\n",
    "- Likely age, gender, location\n",
    "- MBTI/socionics/enneagram guess, neurotype (ASD/ADHD/NT), LGBTQ status, mog score, meme subculture\n",
    "- Socioeconomic status, social life, favorite memes, platforms, cringe/elite factor\n",
    "- Full clinical summary\n",
    "- Be explicit, irreverent, detailed, and brutally honest.\n",
    "\n",
    "Here‚Äôs their actual music data:\n",
    "{music_data}\n",
    "\n",
    "Absolutely no \"diversity-washing\" or LinkedIn-safe answers.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 4. Run the model and display output\n",
    "try:\n",
    "    response = ollama.chat(\n",
    "        model='gpt-oss:20b',\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ]\n",
    "    )\n",
    "    print(response['message']['content'])\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error: Could not connect to Ollama or model crashed. Is it running? Try a smaller model if you get OOM.\")\n",
    "\n",
    "\n",
    "# 5. (Optional) Switch to a smaller model example\n",
    "# To run with a smaller model (if RAM is limited):\n",
    "# response = ollama.chat(\n",
    "#     model='gemma3:7b',   # or any smaller model you have pulled\n",
    "#     messages=[\n",
    "#         {'role': 'user', 'content': prompt}\n",
    "#     ]\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "lewagon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
